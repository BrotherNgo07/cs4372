{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNt3lhY7vEVBFXLv/a/WCS6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-nagar/cs4372/blob/main/Recommendation_System_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNf2dAQQNnZO"
      },
      "source": [
        "# Recommendation Systems\n",
        "We will use the surprise library of Python. Details are available at: http://surpriselib.com\n",
        "\n",
        "We will first work through an example using a built-in dataset and then use a custom one.\n",
        "\n",
        "First, ensure that you have the library installed and then load the required packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvbeyqcHNgjl",
        "outputId": "842522a6-0708-419a-a756-ffd97fbd5ed5"
      },
      "source": [
        "!pip install scikit-surprise"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.7.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1633986 sha256=09f4eae1f961fea8bec0a6e0d833bfc3f397137fcde18cd4f0aaf6a2e645e22c\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-vnJ02aOa9S"
      },
      "source": [
        "import io  \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from surprise import NormalPredictor\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise import KNNBaseline\n",
        "from surprise import Dataset\n",
        "from surprise import get_dataset_dir\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import KFold"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39SWtmcqOpuq"
      },
      "source": [
        "For a recommendation system, we require a file containing at least 3 things - userId, itemId, and rating. Any other information is not needed, but can be good for human analysis of results.\n",
        "\n",
        "Let's load the built in ml-100k dataset that contains movies and ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZd8BnboOmse",
        "outputId": "e7b7365b-c372-4fd6-f606-253a332b7849"
      },
      "source": [
        "# Load the movielens-100k dataset (download it if needed),\n",
        "data = Dataset.load_builtin('ml-100k')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] y\n",
            "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0kJP7rEPHYn",
        "outputId": "9904f147-a640-4591-9780-9d45123e9357"
      },
      "source": [
        "# Let's see what files come with the dataset\n",
        "!ls /root/.surprise_data/ml-100k/ml-100k/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allbut.pl  u1.base  u2.test  u4.base  u5.test  ub.base\tu.genre  u.occupation\n",
            "mku.sh\t   u1.test  u3.base  u4.test  ua.base  ub.test\tu.info\t u.user\n",
            "README\t   u2.base  u3.test  u5.base  ua.test  u.data\tu.item\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62q26F3SPvft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85391ecb-0a14-49ab-eff4-3f01e11466a6"
      },
      "source": [
        "# TODO: Show the first 10 lines of the u.data, and u.item files\n",
        "!head -10 /root/.surprise_data/ml-100k/ml-100k/u.data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196\t242\t3\t881250949\n",
            "186\t302\t3\t891717742\n",
            "22\t377\t1\t878887116\n",
            "244\t51\t2\t880606923\n",
            "166\t346\t1\t886397596\n",
            "298\t474\t4\t884182806\n",
            "115\t265\t2\t881171488\n",
            "253\t465\t5\t891628467\n",
            "305\t451\t3\t886324817\n",
            "6\t86\t3\t883603013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaB5-nihRtuS"
      },
      "source": [
        "## Algorithms\n",
        "Let's look at some of the algorithms available with the package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBJ1MkWyRswn"
      },
      "source": [
        "?KNNBaseline"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp2R7SCxSbcy"
      },
      "source": [
        "The nearest neighbor methods works by searching for neighbors using the utility matrix. Let's create a nearest neighbor first by item and user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSiyKhGVP78C",
        "outputId": "ce2dc44d-44e9-41eb-a648-f76e82b802e4"
      },
      "source": [
        "data = Dataset.load_builtin('ml-100k')\n",
        "trainset = data.build_full_trainset()\n",
        "# we are going to use item-item similarity\n",
        "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
        "algo = KNNBaseline(sim_options=sim_options)\n",
        "algo.fit(trainset)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.knns.KNNBaseline at 0x7fa2f59d6590>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilbee2N1TV4H",
        "outputId": "29bcbbef-ac83-4b87-e966-a576843a404a"
      },
      "source": [
        "!head -10 /root/.surprise_data/ml-100k/ml-100k/u.item"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
            "2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\n",
            "3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\n",
            "4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "5|Copycat (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Copycat%20(1995)|0|0|0|0|0|0|1|0|1|0|0|0|0|0|0|0|1|0|0\n",
            "6|Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)|01-Jan-1995||http://us.imdb.com/Title?Yao+a+yao+yao+dao+waipo+qiao+(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "7|Twelve Monkeys (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Twelve%20Monkeys%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|1|0|0|0\n",
            "8|Babe (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Babe%20(1995)|0|0|0|0|1|1|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "9|Dead Man Walking (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Dead%20Man%20Walking%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "10|Richard III (1995)|22-Jan-1996||http://us.imdb.com/M/title-exact?Richard%20III%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|1|0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDqZoURXW-kX"
      },
      "source": [
        "# Id to Name Lookup\n",
        "Let's write a small method that will convert id to name, and name to id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOnbUClBTKlf"
      },
      "source": [
        "def read_item_names():\n",
        "    \"\"\"Read the u.item file from MovieLens 100-k dataset and return two\n",
        "    mappings to convert raw ids into movie names and movie names into raw ids.\n",
        "    \"\"\"\n",
        "\n",
        "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
        "    rid_to_name = {}\n",
        "    name_to_rid = {}\n",
        "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
        "        for line in f:\n",
        "            line = line.split('|')\n",
        "            rid_to_name[line[0]] = line[1]\n",
        "            name_to_rid[line[1]] = line[0]\n",
        "\n",
        "    return rid_to_name, name_to_rid"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8vv_EKmUiIi"
      },
      "source": [
        "# test this function \n",
        "rid_to_name, name_to_rid = read_item_names()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "ApUrTtaKWvhR",
        "outputId": "5eac7b82-335c-4bc5-c944-8b1a44e78703"
      },
      "source": [
        "rid_to_name[\"1\"]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Toy Story (1995)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "5Pl5szE0WynN",
        "outputId": "156500f4-bbf0-4ee6-adf5-64659bbdaead"
      },
      "source": [
        "name_to_rid[\"Twelve Monkeys (1995)\"]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1KEIIY2Xjas",
        "outputId": "f60db674-dc88-49e6-b481-ee309d673e43"
      },
      "source": [
        "# Find top 10 movies similar to movie with id 100\n",
        "\n",
        "movie_inner_id = algo.trainset.to_inner_iid(\"200\")\n",
        "movie_name = rid_to_name[\"200\"]\n",
        "\n",
        "# Retrieve inner ids of the nearest neighbors of Toy Story.\n",
        "movie_neighbors = algo.get_neighbors(movie_inner_id, k=10)\n",
        "\n",
        "# Convert inner ids of the neighbors into names.\n",
        "movie_neighbors = (algo.trainset.to_raw_iid(inner_id)\n",
        "                       for inner_id in movie_neighbors)\n",
        "movie_neighbors = (rid_to_name[rid]\n",
        "                       for rid in movie_neighbors)\n",
        "\n",
        "print()\n",
        "\n",
        "print('The 10 nearest neighbors of ' + movie_name)\n",
        "for movie in movie_neighbors:\n",
        "    print(movie)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The 10 nearest neighbors of Shining, The (1980)\n",
            "Bonnie and Clyde (1967)\n",
            "Godfather: Part II, The (1974)\n",
            "Alien (1979)\n",
            "Godfather, The (1972)\n",
            "Raging Bull (1980)\n",
            "Pulp Fiction (1994)\n",
            "One Flew Over the Cuckoo's Nest (1975)\n",
            "Carrie (1976)\n",
            "Koyaanisqatsi (1983)\n",
            "His Girl Friday (1940)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kcnxpDaZTxL"
      },
      "source": [
        "Let's now apply the algorithm and figure out it's accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USd7X5jZX7pX",
        "outputId": "fa261975-3c35-4e77-f1f4-47e0bedc28bc"
      },
      "source": [
        "testset = trainset.build_testset()\n",
        "predictions = algo.test(testset)\n",
        "# RMSE should be low as we are biased\n",
        "accuracy.rmse(predictions, verbose=True)  # ~ 0.68 (which is low)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.4807\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.48071109787164656"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASSc6E5waLOl"
      },
      "source": [
        "Now, let's also try some baseline methods. Follow the code available here:\n",
        "\n",
        "https://github.com/NicolasHug/Surprise/blob/fa7455880192383f01475162b4cbd310d91d29ca/examples/baselines_conf.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwYMS8igapJy"
      },
      "source": [
        "For more elaborate testing and validation, follow steps mentioned here\n",
        "https://github.com/NicolasHug/Surprise/blob/fa7455880192383f01475162b4cbd310d91d29ca/examples/grid_search_usage.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIywdaaWa4t8"
      },
      "source": [
        "# Assignment \n",
        "\n",
        "In this part, you will use the dataset that is provided along with the following Kaggle competition \n",
        "\n",
        "https://www.kaggle.com/arashnic/book-recommendation-dataset\n",
        "\n",
        "\n",
        "I have uploaded the files for you at\n",
        "\n",
        "Ratings file - https://an-utd-course.s3.us-west-1.amazonaws.com/CompDS/Ratings.csv\n",
        "\n",
        "Books file - https://an-utd-course.s3.us-west-1.amazonaws.com/CompDS/Books.csv\n",
        "\n",
        "\n",
        "Follow the steps below to create a recommendation system from this data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fFRYXmGrXOX"
      },
      "source": [
        "# TODO: Read both the data files into Pandas dataframes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q34iXAs_rw0D"
      },
      "source": [
        "# TODO: Answer the following questions:\n",
        "\n",
        "# How many ratings and how many books are there in the dataset\n",
        "\n",
        "# Find the top 10 books have received the highest count of ratings. You should output the id of the book, its title, and the count of ratings received.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4IFExALsZM1"
      },
      "source": [
        "# TODO: Important - You may not be able use the whole dataset for model creation, so you need to create a \n",
        "# smaller sample to proceeed further\n",
        "# Here is what I did:\n",
        "# reviews_short = reviews.sample(n = 1000, random_state = 42)\n",
        "# you can try larger values of n, if the system allows you."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4lAFc8iwBmB"
      },
      "source": [
        "# TODO: Use the data to create a custom dataset in the surprise library\n",
        "# Steps to do this are: https://surprise.readthedocs.io/en/stable/getting_started.html#use-a-custom-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C1mn_LuwNtR"
      },
      "source": [
        "# TODO: Choose a book at random and use the KNNBasic algorithm to find out its 10 closest neighbors. Do the results make\n",
        "# sense?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZGB7wKwxO6q"
      },
      "source": [
        "# TODO: Use ParameterGridSearch on the following algorithms and compare their accuracies. You are free to decide\n",
        "# which specific parameters to use:\n",
        "# 1. KNNBaseline\n",
        "# 2. ALS - Baseline\n",
        "# 3. SGD - Baseline\n",
        "# 4. SVD\n",
        "# You should use a cv value of at least 3 and compare the mean accuracy of each of the algorithms\n",
        "# Comment on whether there is significant differences in the results of the algorithms"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}