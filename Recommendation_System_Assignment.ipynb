{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObkTbIfMNYwD8rmceeRUKl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-nagar/cs4372/blob/main/Recommendation_System_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNf2dAQQNnZO"
      },
      "source": [
        "# Recommendation Systems\n",
        "We will use the surprise library of Python. Details are available at: http://surpriselib.com\n",
        "\n",
        "We will first work through an example using a built-in dataset and then use a custom one.\n",
        "\n",
        "First, ensure that you have the library installed and then load the required packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvbeyqcHNgjl",
        "outputId": "9f1cb10f-7d25-4b2f-c958-9bdbec49c685"
      },
      "source": [
        "!pip install scikit-surprise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 50 kB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1619424 sha256=e87610d04b5ad16115ddb8503437ab6003d6f9f0857bf39378ccf063cfa9ff52\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-vnJ02aOa9S"
      },
      "source": [
        "import io  \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from surprise import NormalPredictor\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise import KNNBaseline\n",
        "from surprise import Dataset\n",
        "from surprise import get_dataset_dir\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39SWtmcqOpuq"
      },
      "source": [
        "For a recommendation system, we require a file containing at least 3 things - userId, itemId, and rating. Any other information is not needed, but can be good for human analysis of results.\n",
        "\n",
        "Let's load the built in ml-100k dataset that contains movies and ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZd8BnboOmse",
        "outputId": "53c71d0a-204f-4a3e-bcea-a8ce07a821c5"
      },
      "source": [
        "# Load the movielens-100k dataset (download it if needed),\n",
        "data = Dataset.load_builtin('ml-100k')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] y\n",
            "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0kJP7rEPHYn",
        "outputId": "ed37cee8-15ba-44f9-e336-74db56bb5ceb"
      },
      "source": [
        "# Let's see what files come with the dataset\n",
        "!ls /root/.surprise_data/ml-100k/ml-100k/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allbut.pl  u1.base  u2.test  u4.base  u5.test  ub.base\tu.genre  u.occupation\n",
            "mku.sh\t   u1.test  u3.base  u4.test  ua.base  ub.test\tu.info\t u.user\n",
            "README\t   u2.base  u3.test  u5.base  ua.test  u.data\tu.item\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62q26F3SPvft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0130f92-7135-4906-91bd-ea535e639f8f"
      },
      "source": [
        "# TODO: Show the first 10 lines of the u.data, and u.item files\n",
        "!head -10 /root/.surprise_data/ml-100k/ml-100k/u.data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196\t242\t3\t881250949\n",
            "186\t302\t3\t891717742\n",
            "22\t377\t1\t878887116\n",
            "244\t51\t2\t880606923\n",
            "166\t346\t1\t886397596\n",
            "298\t474\t4\t884182806\n",
            "115\t265\t2\t881171488\n",
            "253\t465\t5\t891628467\n",
            "305\t451\t3\t886324817\n",
            "6\t86\t3\t883603013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaB5-nihRtuS"
      },
      "source": [
        "## Algorithms\n",
        "Let's look at some of the algorithms available with the package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBJ1MkWyRswn"
      },
      "source": [
        "?KNNBaseline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp2R7SCxSbcy"
      },
      "source": [
        "The nearest neighbor methods works by searching for neighbors using the utility matrix. Let's create a nearest neighbor first by item and user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSiyKhGVP78C",
        "outputId": "ccdc728c-c075-4b0f-dffa-852b7c0380aa"
      },
      "source": [
        "data = Dataset.load_builtin('ml-100k')\n",
        "trainset = data.build_full_trainset()\n",
        "# we are going to use item-item similarity\n",
        "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
        "algo = KNNBaseline(sim_options=sim_options)\n",
        "algo.fit(trainset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.knns.KNNBaseline at 0x7f107286bf10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilbee2N1TV4H",
        "outputId": "0019326e-6289-4344-8036-42feece9df55"
      },
      "source": [
        "!head -10 /root/.surprise_data/ml-100k/ml-100k/u.item"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
            "2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\n",
            "3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\n",
            "4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "5|Copycat (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Copycat%20(1995)|0|0|0|0|0|0|1|0|1|0|0|0|0|0|0|0|1|0|0\n",
            "6|Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)|01-Jan-1995||http://us.imdb.com/Title?Yao+a+yao+yao+dao+waipo+qiao+(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "7|Twelve Monkeys (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Twelve%20Monkeys%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|1|0|0|0\n",
            "8|Babe (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Babe%20(1995)|0|0|0|0|1|1|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "9|Dead Man Walking (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Dead%20Man%20Walking%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "10|Richard III (1995)|22-Jan-1996||http://us.imdb.com/M/title-exact?Richard%20III%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|1|0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDqZoURXW-kX"
      },
      "source": [
        "# Id to Name Lookup\n",
        "Let's write a small method that will convert id to name, and name to id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOnbUClBTKlf"
      },
      "source": [
        "def read_item_names():\n",
        "    \"\"\"Read the u.item file from MovieLens 100-k dataset and return two\n",
        "    mappings to convert raw ids into movie names and movie names into raw ids.\n",
        "    \"\"\"\n",
        "\n",
        "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
        "    rid_to_name = {}\n",
        "    name_to_rid = {}\n",
        "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
        "        for line in f:\n",
        "            line = line.split('|')\n",
        "            rid_to_name[line[0]] = line[1]\n",
        "            name_to_rid[line[1]] = line[0]\n",
        "\n",
        "    return rid_to_name, name_to_rid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8vv_EKmUiIi"
      },
      "source": [
        "# test this function \n",
        "rid_to_name, name_to_rid = read_item_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "ApUrTtaKWvhR",
        "outputId": "69fef314-7ad5-466f-b999-96dd31a202d0"
      },
      "source": [
        "rid_to_name[\"1\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Toy Story (1995)'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "5Pl5szE0WynN",
        "outputId": "b910057b-0ec2-499c-9967-8a9042012eb0"
      },
      "source": [
        "name_to_rid[\"Twelve Monkeys (1995)\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'7'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1KEIIY2Xjas",
        "outputId": "19975293-1052-4bb4-ef9b-f9855292ff90"
      },
      "source": [
        "# Find top 10 movies similar to movie with id 100\n",
        "\n",
        "toy_story_inner_id = algo.trainset.to_inner_iid(\"100\")\n",
        "movie_name = rid_to_name[\"100\"]\n",
        "\n",
        "# Retrieve inner ids of the nearest neighbors of Toy Story.\n",
        "toy_story_neighbors = algo.get_neighbors(toy_story_inner_id, k=10)\n",
        "\n",
        "# Convert inner ids of the neighbors into names.\n",
        "toy_story_neighbors = (algo.trainset.to_raw_iid(inner_id)\n",
        "                       for inner_id in toy_story_neighbors)\n",
        "toy_story_neighbors = (rid_to_name[rid]\n",
        "                       for rid in toy_story_neighbors)\n",
        "\n",
        "print()\n",
        "\n",
        "print('The 10 nearest neighbors of ' + movie_name)\n",
        "for movie in toy_story_neighbors:\n",
        "    print(movie)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The 10 nearest neighbors of Fargo (1996)\n",
            "To Die For (1995)\n",
            "Lone Star (1996)\n",
            "Bullets Over Broadway (1994)\n",
            "Sling Blade (1996)\n",
            "People vs. Larry Flynt, The (1996)\n",
            "This Is Spinal Tap (1984)\n",
            "Quiz Show (1994)\n",
            "Mighty Aphrodite (1995)\n",
            "2001: A Space Odyssey (1968)\n",
            "Dolores Claiborne (1994)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kcnxpDaZTxL"
      },
      "source": [
        "Let's now apply the algorithm and figure out it's accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USd7X5jZX7pX",
        "outputId": "9578f3b1-731d-4e52-c1f4-694c65ecaa65"
      },
      "source": [
        "testset = trainset.build_testset()\n",
        "predictions = algo.test(testset)\n",
        "# RMSE should be low as we are biased\n",
        "accuracy.rmse(predictions, verbose=True)  # ~ 0.68 (which is low)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.4807\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.48071109787164656"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASSc6E5waLOl"
      },
      "source": [
        "Now, let's also try some baseline methods. Follow the code available here:\n",
        "\n",
        "https://github.com/NicolasHug/Surprise/blob/fa7455880192383f01475162b4cbd310d91d29ca/examples/baselines_conf.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwYMS8igapJy"
      },
      "source": [
        "For more elaborate testing and validation, follow steps mentioned here\n",
        "https://github.com/NicolasHug/Surprise/blob/fa7455880192383f01475162b4cbd310d91d29ca/examples/grid_search_usage.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIywdaaWa4t8"
      },
      "source": [
        "# Assignment \n",
        "\n",
        "In this part, you will use the dataset that is provided along with the following Kaggle competition \n",
        "\n",
        "https://www.kaggle.com/arashnic/book-recommendation-dataset\n",
        "\n",
        "\n",
        "I have uploaded the files for you at\n",
        "\n",
        "Ratings file - https://an-utd-course.s3.us-west-1.amazonaws.com/CompDS/Ratings.csv\n",
        "\n",
        "Books file - https://an-utd-course.s3.us-west-1.amazonaws.com/CompDS/Books.csv\n",
        "\n",
        "\n",
        "Follow the steps below to create a recommendation system from this data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fFRYXmGrXOX"
      },
      "source": [
        "# TODO: Read both the data files into Pandas dataframes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q34iXAs_rw0D"
      },
      "source": [
        "# TODO: Answer the following questions:\n",
        "\n",
        "# How many ratings and how many books are there in the dataset\n",
        "\n",
        "# Find the top 10 books have received the highest count of ratings. You should output the id of the book, its title, and the count of ratings received.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4IFExALsZM1"
      },
      "source": [
        "# TODO: Important - You may not be able use the whole dataset for model creation, so you need to create a \n",
        "# smaller sample to proceeed further\n",
        "# Here is what I did:\n",
        "# reviews_short = reviews.sample(n = 1000, random_state = 42)\n",
        "# you can try larger values of n, if the system allows you."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4lAFc8iwBmB"
      },
      "source": [
        "# TODO: Use the data to create a custom dataset in the surprise library\n",
        "# Steps to do this are: https://surprise.readthedocs.io/en/stable/getting_started.html#use-a-custom-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C1mn_LuwNtR"
      },
      "source": [
        "# TODO: Choose a book at random and use the KNNBasic algorithm to find out its 10 closest neighbors. Do the results make\n",
        "# sense?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZGB7wKwxO6q"
      },
      "source": [
        "# TODO: Use ParameterGridSearch on the following algorithms and compare their accuracies. You are free to decide\n",
        "# which specific parameters to use:\n",
        "# 1. KNNBaseline\n",
        "# 2. ALS - Baseline\n",
        "# 3. SGD - Baseline\n",
        "# 4. SVD\n",
        "# You should use a cv value of at least 3 and compare the mean accuracy of each of the algorithms\n",
        "# Comment on whether there is significant differences in the results of the algorithms"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}